{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2c08ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5d70a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b404933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbceda32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to plot accuracy and loss\n",
    "\n",
    "def plot_accuracy_loss(training_results): \n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(training_results['training_loss'], 'r')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title('training loss iterations')\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(training_results['validation_accuracy'])\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epochs')   \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7adf6eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to plot model parameters\n",
    "\n",
    "def print_model_parameters(model):\n",
    "    count = 0\n",
    "    for ele in model.state_dict():\n",
    "        count += 1\n",
    "        if count % 2 != 0:\n",
    "            print (\"The following are the parameters for the layer \", count // 2 + 1)\n",
    "        if ele.find(\"bias\") != -1:\n",
    "            print(\"The size of bias: \", model.state_dict()[ele].size())\n",
    "        else:\n",
    "            print(\"The size of weights: \", model.state_dict()[ele].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "047f8ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Neural Network class\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "\n",
    "    # Prediction    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.linear1(x))  \n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b26218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, train_loader, validation_loader, optimizer, epochs=100):\n",
    "    i = 0\n",
    "    useful_stuff = {'training_loss': [],'validation_accuracy': []}  \n",
    "    for epoch in range(epochs):\n",
    "        for i, (x, y) in enumerate(train_loader): \n",
    "            optimizer.zero_grad()\n",
    "            z = model(x.view(-1, 28 * 28))\n",
    "            loss = criterion(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "             #loss for every iteration\n",
    "            useful_stuff['training_loss'].append(loss.data.item())\n",
    "        correct = 0\n",
    "        for x, y in validation_loader:\n",
    "            #validation \n",
    "            z = model(x.view(-1, 28 * 28))\n",
    "            _, label = torch.max(z, 1)\n",
    "            correct += (label == y).sum().item()\n",
    "        accuracy = 100 * (correct / len(validation_dataset))\n",
    "        useful_stuff['validation_accuracy'].append(accuracy)\n",
    "    return useful_stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70aad30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"/home/veroastro/Documents/NASA_POWER_ds/data/\"\n",
    "df = pd.read_csv(filepath + \"POWER_Point_Hourly_20010101_20211231_041d39N_002d17E_UTC.csv\")\n",
    "df_new = df.drop(['T2MWET','T2MDEW', 'PS'], axis = 1) # dropped to deal with multicollinearity\n",
    "X = df_new.drop('T2M', axis= 1)\n",
    "y = df_new['T2M']\n",
    "size =len(X.columns)\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79984ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fde0ecbdb80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create training dataset\n",
    "\n",
    "class PrepareData(Dataset):\n",
    "\n",
    "    def __init__(self, X, y, scale_X=True):\n",
    "        if not torch.is_tensor(X):\n",
    "            if scale_X:\n",
    "                X = StandardScaler().fit_transform(X)\n",
    "                self.X = torch.tensor(X)\n",
    "        if not torch.is_tensor(y):\n",
    "            self.y = torch.tensor(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "train, test = train_test_split(list(range(X.shape[0])), test_size=.3)\n",
    "\n",
    "ds = PrepareData(X, y, scale_X=True)\n",
    "\n",
    "train_set = DataLoader(ds, batch_size=100,\n",
    "                       sampler=SubsetRandomSampler(train))\n",
    "test_set = DataLoader(ds, batch_size=100,\n",
    "                      sampler=SubsetRandomSampler(test))\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c67e0e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create criterion function\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "843b1a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model with 100 neurons\n",
    "\n",
    "input_dim = 11\n",
    "hidden_dim = 100\n",
    "output_dim = 1\n",
    "\n",
    "model = Net(input_dim, hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b56ce5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are the parameters for the layer  1\n",
      "The size of weights:  torch.Size([100, 11])\n",
      "The size of bias:  torch.Size([100])\n",
      "The following are the parameters for the layer  2\n",
      "The size of weights:  torch.Size([1, 100])\n",
      "The size of bias:  torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# Print the parameters for model\n",
    "\n",
    "print_model_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49f7758e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the learning rate and the optimizer\n",
    "\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34110086",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19568/2933688627.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtraining_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "training_results = train(model, criterion, train_set, test_set, optimizer, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2b3056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy and loss\n",
    "\n",
    "plot_accuracy_loss(training_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38699ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
